---
layout: blog
time-series-process: true
mathjax: true
date:   2021-11-26
background-image: https://7568.github.io/images/2021-11-26-tabnet/img.png
title:  TabNet - Attentive Interpretable Tabular Learning
category: time series å¤„ç†
tags:
- tabular data
- time series
---

[tabnet-architecture]:https://7568.github.io/images/2021-11-26-tabnet/tabnet-architecture.png
[sparsemax-compare-softmax]:https://7568.github.io/images/2021-11-26-tabnet/sparsemax-compare-softmax.png
[all-samples]:https://7568.github.io/images/2021-11-26-tabnet/all-samples.png
[self-supervised-process]:https://7568.github.io/images/2021-11-26-tabnet/self-supervised-process.png
[tabnet-encoder-1]:https://7568.github.io/images/2021-11-26-tabnet/tabnet-encoder-1.png
[tabnet-feature-transformer]:https://7568.github.io/images/2021-11-26-tabnet/tabnet-feature-transformer.png
[tabnet-attentive-transformer]:https://7568.github.io/images/2021-11-26-tabnet/tabnet-attentive-transformer.png

# ç®€ä»‹

TabNet æ˜¯2020å¹´ Google Cloud AI å›¢é˜Ÿå‘è¡¨çš„ä¸€ç¯‡ç”¨æ¥å¤„ç†è¡¨æ ¼æ•°æ®çš„æ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œå®ƒå¯è§£é‡Šæ€§å¼ºè€Œä¸”ä½¿ç”¨åˆ°äº†è‡ªç›‘ç£æŠ€æœ¯ï¼Œæœ¬æ–‡å°†
é€šè¿‡[ğŸ’ ğŸ’ ğŸ’ è®ºæ–‡ ğŸ’ ğŸ’ ğŸ’](https://arxiv.org/pdf/1908.07442.pdf) å’Œ[ğŸ’ ğŸ’ ğŸ’ ä»£ç  ğŸ’ ğŸ’ ğŸ’(éå®˜æ–¹)](https://github.com/dreamquark-ai/tabnet) æ¥å¯¹ TabNet è¿›è¡Œä»‹ç»ã€‚

# è®ºæ–‡ä»‹ç»

å¯¹äºå¤„ç† tabular ç±»å‹çš„æ•°æ®ï¼Œç›®å‰ä½¿ç”¨åŸºäºæ ‘ç»“æ„çš„é›†æˆå­¦ä¹ æ¡†æ¶ä¼šæœ‰å¾ˆå¥½çš„æ•ˆæœã€‚ä¾‹å¦‚ [ğŸ’ LightGBM ğŸ’](#LightGBM) å’Œ [ğŸ’ XDBoost ğŸ’](#XDBoost) åœ¨ä¼—å¤š tabular ç±»å‹çš„æ•°æ®å¤„ç†ä»»åŠ¡ä¸­éƒ½æœ‰ç²¾å½©çš„è¡¨ç°ã€‚
ä½†æ˜¯ TabNet æœ‰è‡ªå·±çš„ä¼˜ç‚¹ï¼Œè€Œä¸”åœ¨å¾ˆå¤šä»»åŠ¡ä¸­æ•ˆæœå¹¶ä¸æ¯”å®ƒä»¬å·®ã€‚

TabNet ä¼˜ç‚¹å¦‚ä¸‹ï¼š
1. æ–¹ä¾¿ä½¿ç”¨ï¼Œå¯¹åŸå§‹æ•°æ®ä¸éœ€è¦åšä»»ä½•å…¶ä»–çš„æ“ä½œï¼Œå°±èƒ½ç›´æ¥ä½¿ç”¨ï¼Œè€Œä¸” TabNet æ˜¯ç«¯å¯¹ç«¯çš„ï¼Œè®­ç»ƒèµ·æ¥éå¸¸æ–¹ä¾¿ã€‚
2. TabNet ä½¿ç”¨ attention æœºåˆ¶ï¼Œä½¿å¾—æ¨¡å‹çš„è§£é‡Šæ€§å¼ºã€‚
3. TabNet æ•ˆæœå¥½ï¼Œå¹¶ä¸”æœ‰ä¸¤ç§ä¸åŒçš„å¯è§£é‡Šæ€§ï¼Œä¸€ä¸ªæ˜¯å±€éƒ¨å¯è§£é‡Šæ€§ï¼Œä¸€ä¸ªæ˜¯å…¨å±€å¯è§£é‡Šæ€§ã€‚
4. å¯¹äºç¬¬ä¸€æ¬¡é‡è§çš„ tabular ç±»å‹çš„æ•°æ®ï¼Œæˆ‘ä»¬ä½¿ç”¨éç›‘ç£å¡«è¯æ¸¸æˆçš„æ–¹å¼å¯¹æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œä½¿å¾—æ¨¡å‹åœ¨è¯¥æ•°æ®ä¸Šèƒ½æœ‰å¾ˆå¥½çš„è¡¨ç°ã€‚

æ‰€è°“éç›‘ç£å¡«è¯æ¸¸æˆå°±æ˜¯æŠŠæ ·æœ¬æ•°æ®éšæœºçš„é€‰æ‹©ä¸€äº›å±æ€§ç½®ä¸ºç©ºï¼Œç„¶åè®©ç½‘ç»œæ¥è¿›è¡Œé¢„æµ‹å­¦ä¹ ã€‚å½“ç½‘ç»œå¯¹è¯¥æ•°æ®çš„å¡«è¯æ¸¸å·²ç»å¤„ç†å¾—
å¾ˆå¥½ä¹‹åï¼Œç„¶åå†æ¥è¿›è¡Œå¯¹è¯¥æ•°æ®çš„å®é™…ä»»åŠ¡çš„å¾®è°ƒè®­ç»ƒï¼Œä»è€Œæé«˜ç½‘ç»œåœ¨å®é™…ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚é€šå¸¸æˆ‘ä»¬å¯ä»¥æŠŠè¿™ç§é¢„è®­ç»ƒå¥½çš„æ¨¡å‹
å½“ä½œæ•´ä¸ªç½‘ç»œçš„ embedding å±‚ã€‚

ä¸‹å›¾å±•ç¤ºäº† TabNet çš„æ•´ä½“ç»“æ„

![tabnet-architecture]

æ•´ä½“åˆ†ä¸º encoder å’Œ decoder ä¸¤éƒ¨åˆ†ï¼Œåœ¨ encoder ä¸­æœ‰ä¸‰ä¸ªç‰¹æ®Šçš„ç»“æ„ï¼Œåˆ†åˆ«ä¸º feature transformerï¼Œattentive transformerå’Œ feature maskingï¼Œå…¶ä¸­ feature transformer æ˜¯
ç”¨æ¥è¿›è¡Œç‰¹å¾æå–ï¼Œattentive transformer æ˜¯ç”¨æ¥è¿›è¡Œç‰¹å¾é€‰æ‹©ï¼Œå’Œæä¾›å¯¹æ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Œè€Œ feature masking æ˜¯ç”¨æ¥è·å–å…¨å±€ç‰¹å¾é‡è¦æ€§çš„åˆ†å¸ƒã€‚
å›¾ä¸­çš„ï¼ˆaï¼‰æ˜¯ encoder ç»“æ„ï¼Œï¼ˆbï¼‰æ˜¯ decoder ç»“æ„ï¼Œï¼ˆcï¼‰æ˜¯ feature transformerï¼Œé‡Œé¢å¯ä»¥åˆ†æˆ4å±‚ï¼Œæ¯ä¸€å±‚éƒ½æ˜¯ç”± FCï¼ŒBNï¼Œ[ğŸ’ GLU ğŸ’](https://7568.github.io/2021/11/15/cnn-seq2seqModel.html#glu) æ„æˆã€‚å…¶ä¸­å‰2å±‚ä¸º Shared across decision stepsï¼Œå¦å¤–ä¸¤å±‚ä¸º Decision step dependentï¼Œ
ï¼ˆdï¼‰æ˜¯ attentive transformer ç»“æ„ï¼Œé‡Œé¢çš„ [ğŸ’ sparsemax ğŸ’](https://arxiv.org/pdf/1602.02068) ç”¨æ¥åšå½’ä¸€åŒ–å¤„ç†ï¼Œå¹¶ä¸”ç»“æœä¸­åªåŒ…å«çªå‡ºçš„ç‰¹å¾ä¿¡æ¯ã€‚

å…¶ä¸­åœ¨ï¼ˆaï¼‰ä¸­ï¼Œæœ‰ä¸€ä¸ªå°† Relu å…ˆ Agg. ç„¶åå†ä¸ Mask ç›¸ä¹˜çš„æ“ä½œï¼Œæœ€ç»ˆçš„åˆ° Feature attributesï¼Œè¯¥æ“ä½œæ˜¯ä¸ºäº†åšå±•ç¤ºç”¨çš„ï¼Œè®­ç»ƒçš„æ—¶å€™ä¸ä¼šç”¨åˆ°å®ƒï¼Œæ‰€ä»¥å¯ä»¥å…ˆä¸ç®¡ã€‚

## Self-supervised

è‡ªç›‘ç£å­¦ä¹ åœ¨æœºå™¨å­¦ä¹ æ–‡æœ¬ä»»åŠ¡ä¸­çš„ä¸€ä¸ªå¸¸ç”¨çš„å­¦ä¹ ç­–ç•¥ï¼Œé€šå¸¸è‡ªç›‘ç£å­¦ä¹ éƒ½æ˜¯ä½¿ç”¨å¡«è¯æ¸¸æˆæ¥è¿›è¡Œçš„ã€‚ä¸‹å›¾å±•ç¤ºçš„æ˜¯è‡ªç›‘ç£å­¦ä¹ çš„è¿‡ç¨‹ã€‚

![self-supervised-process]

å·¦è¾¹æ˜¯è‡ªç›‘ç£å­¦ä¹ çš„è¿‡ç¨‹ï¼Œé¦–å…ˆå°†è¾“å…¥æ ·æœ¬éšæœºçš„ mask ä½ä¸€éƒ¨åˆ†å†…å®¹ï¼Œç„¶åæ”¾å…¥ encoderï¼Œå¾—åˆ°è¾“å…¥æ ·æœ¬çš„ featuresï¼Œå†è¿›è¡Œ decoder ï¼Œé¢„æµ‹ mask æ‰çš„ä½ç½®çš„å€¼ï¼Œè¿›è¡Œè®­ç»ƒã€‚
å½“æˆ‘ä»¬å·¦è¾¹çš„ä»»åŠ¡è®­ç»ƒå¥½ä¹‹åï¼Œå°±å¼€å§‹å³è¾¹çš„è®­ç»ƒï¼Œæ­¤æ—¶è¾“å…¥æ ·æœ¬æ²¡æœ‰ maskï¼Œæ”¾å…¥åˆ°åœ¨å·¦è¾¹è®­ç»ƒå¥½äº†çš„ encoder ä¹‹åï¼Œå¾—åˆ°æ ·æœ¬çš„ featuresï¼Œç„¶åæ”¾å…¥åˆ°ä¸€ä¸ªåˆ†ç±»ç½‘ç»œä¸­ï¼Œå¾—åˆ°æˆ‘ä»¬åˆ†ç±»ä»»åŠ¡çš„ç»“æœã€‚
é€šè¿‡å¾®è°ƒæˆ‘ä»¬çš„å³è¾¹çš„ç½‘ç»œï¼Œå°±èƒ½å¾—åˆ°ä¸€ä¸ªæ¯”è¾ƒå¥½çš„æ•ˆæœã€‚

## sparsemax

sparsemax å¸¸ç”¨äºå¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œé€šå¸¸å½“ä½œç¥ç»ç½‘ç»œçš„æ¿€æ´»å‡½æ•°æ”¾åœ¨æœ€åä¸€å±‚å–ä»£ softmaxã€‚sparsemax å’Œ softmax çš„åŒºåˆ«å¦‚ä¸‹ï¼š

![sparsemax-compare-softmax]

ä¸ªäººç†è§£ sparsemax çš„ä¼˜åŠ¿æ˜¯åœ¨å¤šåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œä½¿ç”¨ sparsemax èƒ½å¤Ÿå¹³è¡¡ä¸€ä¸ªæ ·æœ¬å±äºå¤šä¸ªåˆ†ç±»çš„æƒé‡ï¼Œè€Œåœ¨ softmax ä¸­
ä¸€ä¸ªæ ·æœ¬è™½ç„¶å¯èƒ½å±äºå¤šä¸ªç±»åˆ«ï¼Œä½†æ˜¯ä»–ä»¬çš„æƒé‡å´æ˜¯ä¸ä¸€æ ·çš„ã€‚ä¾‹å¦‚æŸä¸€ä¸ªæ ·æœ¬å±äº1ï¼Œ2ä¸¤ä¸ªç±»åˆ«ï¼Œå¦‚æœæˆ‘ä»¬çš„ç½‘ç»œç®—å¾—è¯¥æ ·æœ¬åœ¨ç±»åˆ«1ï¼Œ2ä¸Šçš„
softmax å€¼åˆ†åˆ«ä¸º0.7å’Œ0.9ï¼Œè€Œä¸”è¿™ä¸¤ä¸ªå€¼ä¹Ÿæ˜¯æœ€å¤§çš„ä¸¤ä¸ªå€¼ï¼Œè™½ç„¶æœ€ç»ˆç»“æœèƒ½å¾—å‡ºè¯¥æ ·æœ¬å±äº1ï¼Œ2ä¸¤ä¸ªç±»åˆ«ï¼Œä½†æ˜¯å…¶å®
ç½‘ç»œåœ¨åå‘æ±‚å¯¼çš„è¿‡ç¨‹ä¸­è¿˜æ˜¯ä¼šæƒ©ç½šè¿™ä¸¤ä¸ªè¾“å‡ºï¼Œå› ä¸ºä»–ä»¬ä¸æ˜¯1ï¼Œè€Œå¦‚æœä½¿ç”¨ sparsemax å°±ä¸ä¼šè¿™æ ·ï¼Œç»“æœä¹Ÿæ˜¯èƒ½å¤Ÿå¾—å‡ºè¯¥æ ·æœ¬
å±äº1ï¼Œ2ä¸¤ä¸ªç±»åˆ«ï¼Œè€Œä¸”åå‘çš„æ—¶å€™ä¸ä¼šå¯¹å®ƒä»¬è¿›è¡Œæƒ©ç½šã€‚æ‰€ä»¥ sparsemax åœ¨æŸäº›åº”ç”¨ä¸­ä¼¼ä¹ä¼šæ›´åŠ åˆç†ä¸€äº›ã€‚

## LightGBM

TODO

## XDBoost

TODO

## gradient-boosted DT

TODO

# ä»£ç 

åœ¨ [ğŸ’ dreamquark-ai ğŸ’](https://github.com/dreamquark-ai/tabnet) çš„ tabnet å®ç°ä»£ç ä¸­æœ‰7ä¸ª example ï¼Œä»–ä»¬åˆ†åˆ«æ˜¯ï¼š
- tabnet å¯¹ç¾å›½äººå£æ•°æ®åˆ†ç±»é¢„æµ‹çš„åŸºæœ¬ä½¿ç”¨ä»‹ç» [ğŸ’ census_example.ipynb ğŸ’](https://github.com/dreamquark-ai/tabnet/blob/develop/census_example.ipynb)
- è‡ªå®šä¹‰è§„åˆ™çš„ tabnet åˆ†ç±»é¢„æµ‹ä½¿ç”¨ä»‹ç»ï¼Œ[ğŸ’ customizing_example.py ğŸ’](https://github.com/dreamquark-ai/tabnet/blob/develop/customizing_example.py)
- tabnet å¯¹æ£®æ—è¦†ç›–ç‡æ•°æ®åˆ†ç±»é¢„æµ‹çš„åŸºæœ¬ä½¿ç”¨ä»‹ç» [ğŸ’ forest_example.py ğŸ’](https://github.com/dreamquark-ai/tabnet/blob/develop/forest_example.py)
- tabnet å¯¹å›å½’æ•°æ®çš„åŸºæœ¬ä½¿ç”¨ä»‹ç» [ğŸ’ regression_example.py ğŸ’](https://github.com/dreamquark-ai/tabnet/blob/develop/regression_example.py)
- tabnet å¯¹å¤šåˆ†ç±»ä»»åŠ¡çš„ä½¿ç”¨ä»‹ç» [ğŸ’ multi_task_example.py ğŸ’](https://github.com/dreamquark-ai/tabnet/blob/develop/multi_task_example.py)
- tabnet å¯¹å¤šå›å½’ä»»åŠ¡çš„ä½¿ç”¨ä»‹ç» [ğŸ’ multi_regression_example.py ğŸ’](https://github.com/dreamquark-ai/tabnet/blob/develop/multi_regression_example.py)
- å¸¦è‡ªç›‘ç£çš„é¢„è®­ç»ƒæ¨¡å‹çš„tabnetå¯¹åˆ†ç±»ä»»åŠ¡çš„ä½¿ç”¨ä»‹ç» [ğŸ’ pretraining_example.py ğŸ’](https://github.com/dreamquark-ai/tabnet/blob/develop/pretraining_example.py)

æœ¬æ¥ä¸Šé¢çš„ä»£ç ï¼Œå¯¹ tabnet çš„åŸºæœ¬çš„ä½¿ç”¨æ˜¯æ²¡é—®é¢˜çš„ï¼Œä½†æ˜¯åšç ”ç©¶ä¸èƒ½åªæ˜¯ä¼šç”¨ï¼Œè¿˜å¾—ææ˜ç™½åˆ«äººæ˜¯æ€ä¹ˆå®ç°çš„ã€‚æ‰€ä»¥æ¥ä¸‹æ¥æˆ‘å°†é‡æ–°æ”¹å†™ä¸€ä¸‹ä¸Šé¢çš„ä»£ç ï¼Œå°†è°ƒç”¨æ¥å£çš„åœ°æ–¹å…¨éƒ¨æ”¹æˆæ–¹æ³•çš„å®ç°ã€‚
è™½ç„¶æœ€åæˆ‘ç»å¤§éƒ¨åˆ†çš„ä»£ç è¿˜æ˜¯ä½¿ç”¨çš„ [ğŸ’ dreamquark-ai ğŸ’](https://github.com/dreamquark-ai/tabnet) ä¸­æä¾›çš„ï¼Œä½†æ˜¯æˆ‘ä»£ç å®ç°çš„ç›®çš„ä¸ä¸€æ ·ï¼Œè§‚ä¼—çœ‹æˆ‘çš„ä»£ç çš„è¯èƒ½æ›´å¥½çš„ç†è§£ tabnet çš„åŸç†å’Œå®ç°æ–¹æ³•ï¼Œ
è€Œ [ğŸ’ dreamquark-ai ğŸ’](https://github.com/dreamquark-ai/tabnet) çš„ä»£ç ä¸»è¦æ˜¯æ–¹ä¾¿åˆ«äººä½¿ç”¨ï¼Œæ‰€ä»¥é‡Œé¢ä¼šæœ‰å¾ˆå¤šåœ°æ–¹åšäº†å„ç§å°è£…å„ç§æ¥å£åŒ–ï¼Œå¯¹äºæƒ³å­¦ä¹  tabnet çš„äººæ¥è¯´æ˜¯å¾ˆä¸å‹å¥½çš„ã€‚

*NOTE:* æœ¬æ–‡ä¸ä¼šåˆ—å‡ºæ‰€æœ‰çš„ä»£ç ï¼Œåªä¼šåˆ—å‡ºå…³é”®çš„ä»£ç ï¼Œç‚¹å‡»[ğŸ’ å®Œæ•´ä»£ç  ğŸ’]() å¯ä¸‹è½½å®Œæ•´çš„ä»£ç ã€‚å¸¦è‡ªç›‘ç£å­¦ä¹ çš„ç½‘ç»œï¼Œåˆ†æˆè‡ªç›‘ç£è®­ç»ƒå’Œå¾®è°ƒä¸¤ä¸ªéƒ¨åˆ†ï¼Œå…¶ä¸­å¾®è°ƒéƒ¨åˆ†çš„ä»£ç å®ç°å’Œä¸å¸¦è‡ªç›‘ç£å­¦ä¹ çš„è¿‡ç¨‹æ˜¯ä¸€æ ·çš„ï¼Œæ‰€ä»¥æœ¬æ–‡å°†å…ˆå®ç°ä¸å¸¦è‡ªç›‘ç£çš„åˆ†ç±»ä»»åŠ¡ï¼Œç„¶åå†åŠ ä¸Šè‡ªç›‘ç£çš„ä»£ç ã€‚

## tabnet åŸºæœ¬æ•°æ®åˆ†ç±»ä»»åŠ¡

é¦–å…ˆæ˜¯æ•°æ®å‡†å¤‡ï¼Œæˆ‘ä»¬çš„æ•°æ®æ˜¯ä¸€ä»½ç¾å›½éƒ¨åˆ†äººå£çš„è°ƒæŸ¥æ•°æ®ï¼Œæˆ‘ä»¬çš„ä»»åŠ¡æ˜¯é€šè¿‡è®­ç»ƒè¯¥æ•°æ®æ¥é¢„æµ‹ä¸åŒçš„äººçš„æ”¶å…¥å¹´æ”¶å…¥æ˜¯å¦å¤§äº50Kã€‚å‰10æ¡æ•°æ®å¦‚ä¸‹

![all-samples]

æˆ‘ä»¬æœ€ç»ˆéœ€è¦æ¥é¢„æµ‹ "<=50K" è¿™ä¸ªåˆ—çš„æ•°æ®ã€‚é¦–å…ˆæˆ‘ä»¬æ˜¯è¦è¿›è¡Œç©ºå€¼çš„å¡«å……ï¼Œç„¶åå†å°†å­—ç¬¦ä¸²æ•°æ®è½¬æ¢æˆæ•°ç»„æ•°æ®ï¼Œæœ€åæˆ‘ä»¬å°†æ•°æ®æŒ‰ç…§8ï¼š1ï¼š1çš„æ¯”ä¾‹åˆ†æˆ3ä»½ï¼Œåˆ†åˆ«æ˜¯trainï¼Œvalidationï¼Œå’Œtestã€‚å…¶ä¸­
trainç”¨æ¥è®­ç»ƒï¼Œvalidationç”¨æ¥åœ¨è®­ç»ƒçš„æ—¶å€™æ£€éªŒæ•ˆæœï¼Œtestç”¨æ¥åœ¨è®­ç»ƒå®Œæˆä¹‹åæ£€éªŒæ•ˆæœã€‚ ä»£ç å¦‚ä¸‹ï¼š
```python
#!/usr/bin/env python
# coding: utf-8
from pytorch_tabnet.tab_model import TabNetClassifier
import torch
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import roc_auc_score
import pandas as pd
import numpy as np
import os
import wget
from pathlib import Path
from matplotlib import pyplot as plt
from torch.utils.data import Dataset
from torch.utils.data import DataLoader, WeightedRandomSampler
from torch.nn import Linear, BatchNorm1d, ReLU
from pytorch_tabnet import sparsemax
from torch.nn.utils import clip_grad_norm_

np.random.seed(1024)

url = "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
dataset_name = 'census-income'
out = Path(os.getcwd() + '/data/' + dataset_name + '.csv')

out.parent.mkdir(parents=True, exist_ok=True)
if out.exists():
    print("File already exists.")
else:
    print("Downloading file...")
    wget.download(url, out.as_posix())

train = pd.read_csv(out)
target = ' <=50K'
if "Set" not in train.columns:
    train["Set"] = np.random.choice(["train", "valid", "test"], p=[.8, .1, .1], size=(train.shape[0],))

train_indices = train[train.Set == "train"].index
valid_indices = train[train.Set == "valid"].index
test_indices = train[train.Set == "test"].index

nunique = train.nunique()
types = train.dtypes

categorical_columns = []
categorical_dims = {}
for col in train.columns:
    if types[col] == 'object' or nunique[col] < 200:
        print(col, train[col].nunique())
        l_enc = LabelEncoder()
        train[col] = train[col].fillna("VV_likely")
        train[col] = l_enc.fit_transform(train[col].values)
        categorical_columns.append(col)
        categorical_dims[col] = len(l_enc.classes_)
    else:
        train.fillna(train.loc[train_indices, col].mean(), inplace=True)

train.loc[train[target] == 0, target] = "wealthy"
train.loc[train[target] == 1, target] = "not_wealthy"

unused_feat = ['Set']

features = [col for col in train.columns if col not in unused_feat + [target]]

cat_idxs = [i for i, f in enumerate(features) if f in categorical_columns]

cat_dims = [categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]

X_train = train[features].values[train_indices]
y_train = train[target].values[train_indices]

X_valid = train[features].values[valid_indices]
y_valid = train[target].values[valid_indices]

X_test = train[features].values[test_indices]
y_test = train[target].values[test_indices]



batch_size = 128
need_shuffle = False
num_workers = 1
drop_last = False
pin_memory = True
max_epochs = 10
cross_entropy_loss = torch.nn.CrossEntropyLoss()
lambda_sparse: float = 1e-3
device = 'cuda' if torch.cuda.is_available() else 'cpu'
# weather clip the gradient , clip the gradient can fix the gradient exploding problems
clip_value = 0

```

æ¥ä¸‹æ¥æˆ‘ä»¬æ„é€ æ•°æ®åŠ è½½å™¨ï¼Œæ–¹ä¾¿è®­ç»ƒå’Œæµ‹è¯•çš„æ—¶å€™ä½¿ç”¨ï¼Œä»£ç å¦‚ä¸‹
```python
class TorchDataset(Dataset):

    def __init__(self, x, y):
        self.x = x
        self.y = y

    def __len__(self):
        return len(self.x)

    def __getitem__(self, index):
        x, y = self.x[index], self.y[index]
        return x, y

train_dataloader = DataLoader(
    TorchDataset(X_train.astype(np.float32), y_train),
    batch_size=batch_size,
    shuffle=need_shuffle,
    num_workers=num_workers,
    drop_last=drop_last,
    pin_memory=pin_memory,
)

eval_set = [(X_train, y_train), (X_valid, y_valid)]
valid_dataloaders = []
for X, y in eval_set:
    valid_dataloaders.append(
        DataLoader(
            TorchDataset(X.astype(np.float32), y),
            batch_size=batch_size,
            shuffle=False,
            num_workers=num_workers,
            pin_memory=pin_memory,
        )
    )
```

æ¥ä¸‹æ¥æˆ‘ä»¬å¼€å§‹è¿›è¡Œæ¨¡å‹çš„æ„é€ ã€‚é¦–å…ˆæˆ‘ä»¬ä»å¤§çš„è§†è§’æ¥æ„å»ºæ¨¡å‹ï¼Œæˆ‘ä»¬å…ˆå®šä¹‰ä¸€ä¸ª TabNet å¯¹è±¡ï¼Œé‡Œé¢åŒ…å«æœ‰ EmbeddingGenerator å’Œ TabNetNoEmbeddings ä¸¤ä¸ªå°çš„å­å¯¹è±¡ã€‚
å…¶ä¸­ EmbeddingGenerator æŒ‡çš„æ˜¯åœ¨æˆ‘ä»¬æŠŠæ•°æ®æ”¾å…¥æ¨¡å‹ä¹‹åå‰çš„æ“ä½œï¼Œåœ¨è®ºæ–‡çš„ç½‘ç»œå›¾ä¸­å…¶å®æ˜¯çœç•¥äº†è¿™ä¸ªæ­¥éª¤çš„ã€‚è®ºæ–‡çš„ç½‘ç»œå›¾çš„è¾“å…¥ç›´æ¥æ˜¯ Features ï¼Œä½†æ˜¯è¯¥ Features å…¶å®æ˜¯å·²ç» embedding ä¹‹åçš„äº†ã€‚
TabNetNoEmbeddings å°±æ˜¯æˆ‘ä»¬è®ºæ–‡ä¸­çš„ç½‘ç»œå›¾çš„ç»“æ„äº†ã€‚åœ¨æœ‰ Self-supervised çš„ç½‘ç»œä¸­ï¼ŒTabNetNoEmbeddings ä¸­åŒ…å«äº† encoder å’Œ decoder ä¸¤ä¸ªæ¨¡å—ï¼Œè€Œåœ¨æ²¡æœ‰ Self-supervised çš„ç½‘ç»œä¸­ ï¼Œ
TabNetNoEmbeddings ä¸­åªåŒ…å« encoderã€‚ç”±äº TabNet ä¸ä»…å¯ä»¥è¿›è¡Œåˆ†ç±»ä»»åŠ¡ï¼Œè¿˜å¯ä»¥è¿›è¡Œå›å½’ä»»åŠ¡ï¼Œæ‰€ä»¥è¿™é‡Œæˆ‘ä»¬çš„åˆ†ç±»å™¨å¹¶ä¸åœ¨ TabNet ä¸­ã€‚

ç°åœ¨å‡è®¾æˆ‘ä»¬æœ‰ä¸€æ¡æ•°æ®ï¼Œ`60, 200000, Bachelors, Exec-managerial, M, Husband` åˆ†åˆ«æŒ‡çš„æ˜¯ `å¹´é¾„, æŠ•èµ„çš„æ”¶ç›Š, å­¦å†, èŒä¸š, æ€§åˆ«, å¤«å¦»è§’è‰²`ï¼Œé¦–å…ˆæˆ‘ä»¬çš„æ•°æ®è¦ç»è¿‡ LabelEncoder å°†å­—ç¬¦æ•°æ®è½¬åŒ–æˆæ•°å­—ä¸º `[1., 0., 0., 8., 0., 3.]`ã€‚

```python
class TabNet(torch.nn.Module):
    def __init__(self, input_dim, output_dim, n_d=8, n_a=8, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[],
                 cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, virtual_batch_size=128, momentum=0.02,
                 mask_type="sparsemax", ):
        """
        Defines TabNet network

        Parameters
        ----------
        input_dim : int
            Initial number of features
        output_dim : int
            Dimension of network output
            examples : one for regression, 2 for binary classification etc...
        n_d : int
            Dimension of the prediction  layer (usually between 4 and 64)
        n_a : int
            Dimension of the attention  layer (usually between 4 and 64)
        n_steps : int
            Number of successive steps in the network (usually between 3 and 10)
        gamma : float
            Float above 1, scaling factor for attention updates (usually between 1.0 to 2.0)
        cat_idxs : list of int
            Index of each categorical column in the dataset
        cat_dims : list of int
            Number of categories in each categorical column
        cat_emb_dim : int or list of int
            Size of the embedding of categorical features
            if int, all categorical features will have same embedding size
            if list of int, every corresponding feature will have specific size
        n_independent : int
            Number of independent GLU layer in each GLU block (default 2)
        n_shared : int
            Number of independent GLU layer in each GLU block (default 2)
        epsilon : float
            Avoid log(0), this should be kept very low
        virtual_batch_size : int
            Batch size for Ghost Batch Normalization
        momentum : float
            Float value between 0 and 1 which will be used for momentum in all batch norm
        mask_type : str
            Either "sparsemax" or "entmax" : this is the masking function to use
        """
        super(TabNet, self).__init__()
        self.cat_idxs = cat_idxs or []
        self.cat_dims = cat_dims or []
        self.cat_emb_dim = cat_emb_dim

        self.input_dim = input_dim
        self.output_dim = output_dim
        self.n_d = n_d
        self.n_a = n_a
        self.n_steps = n_steps
        self.gamma = gamma
        self.epsilon = epsilon
        self.n_independent = n_independent
        self.n_shared = n_shared
        self.mask_type = mask_type

        if self.n_steps <= 0:
            raise ValueError("n_steps should be a positive integer.")
        if self.n_independent == 0 and self.n_shared == 0:
            raise ValueError("n_shared and n_independent can't be both zero.")

        self.virtual_batch_size = virtual_batch_size
        self.embedder = EmbeddingGenerator(input_dim, cat_dims, cat_idxs, cat_emb_dim)
        self.post_embed_dim = self.embedder.post_embed_dim
        self.tabnet = TabNetNoEmbeddings(self.post_embed_dim, output_dim, n_d, n_a, n_steps, gamma, n_independent,
                                         n_shared, epsilon, virtual_batch_size, momentum, mask_type, )

    def forward(self, x):
        x = self.embedder(x)
        return self.tabnet(x)

    def forward_masks(self, x):
        x = self.embedder(x)
        return self.tabnet.forward_masks(x)

```

ç„¶åå°†`[1., 0., 0., 8., 0., 3.]`æ”¾å…¥åˆ° EmbeddingGenerator ä¸­ï¼Œå¾—åˆ° `[-1.1524, -0.5344, -0.3433,  0.3956,  0.4631,  1.1878]`ã€‚

è¾“å…¥å±æ€§ç¼–ç  EmbeddingGenerator çš„ä»£ç å¦‚ä¸‹ï¼Œè¯¥å±æ€§ç¼–ç æ˜¯å¯ä»¥é€šè¿‡ç½‘ç»œæ¥å­¦ä¹ çš„ã€‚
```python
class EmbeddingGenerator(torch.nn.Module):
    """
    Classical embeddings generator
    """

    def __init__(self, input_dim, cat_dims, cat_idxs, cat_emb_dim):
        """This is an embedding module for an entire set of features

        Parameters
        ----------
        input_dim : int
            Number of features coming as input (number of columns)
        cat_dims : list of int
            Number of modalities for each categorial features
            If the list is empty, no embeddings will be done
        cat_idxs : list of int
            Positional index for each categorical features in inputs
        cat_emb_dim : int or list of int
            Embedding dimension for each categorical features
            If int, the same embedding dimension will be used for all categorical features
        """
        super(EmbeddingGenerator, self).__init__()
        if cat_dims == [] and cat_idxs == []:
            self.skip_embedding = True
            self.post_embed_dim = input_dim
            return
        elif (cat_dims == []) ^ (cat_idxs == []):
            if cat_dims == []:
                msg = "If cat_idxs is non-empty, cat_dims must be defined as a list of same length."
            else:
                msg = "If cat_dims is non-empty, cat_idxs must be defined as a list of same length."
            raise ValueError(msg)
        elif len(cat_dims) != len(cat_idxs):
            msg = "The lists cat_dims and cat_idxs must have the same length."
            raise ValueError(msg)

        self.skip_embedding = False
        if isinstance(cat_emb_dim, int):
            self.cat_emb_dims = [cat_emb_dim] * len(cat_idxs)
        else:
            self.cat_emb_dims = cat_emb_dim

        # check that all embeddings are provided
        if len(self.cat_emb_dims) != len(cat_dims):
            msg = f"""cat_emb_dim and cat_dims must be lists of same length, got {len(self.cat_emb_dims)}
                      and {len(cat_dims)}"""
            raise ValueError(msg)
        self.post_embed_dim = int(
            input_dim + np.sum(self.cat_emb_dims) - len(self.cat_emb_dims)
        )

        self.embeddings = torch.nn.ModuleList()

        # Sort dims by cat_idx
        sorted_idxs = np.argsort(cat_idxs)
        cat_dims = [cat_dims[i] for i in sorted_idxs]
        self.cat_emb_dims = [self.cat_emb_dims[i] for i in sorted_idxs]

        for cat_dim, emb_dim in zip(cat_dims, self.cat_emb_dims):
            self.embeddings.append(torch.nn.Embedding(cat_dim, emb_dim))

        # record continuous indices
        self.continuous_idx = torch.ones(input_dim, dtype=torch.bool)
        self.continuous_idx[cat_idxs] = 0

    def forward(self, x):
        """
        Apply embeddings to inputs
        Inputs should be (batch_size, input_dim)
        Outputs will be of size (batch_size, self.post_embed_dim)
        """
        if self.skip_embedding:
            # no embeddings required
            return x

        cols = []
        cat_feat_counter = 0
        for feat_init_idx, is_continuous in enumerate(self.continuous_idx):
            # Enumerate through continuous idx boolean mask to apply embeddings
            if is_continuous:
                cols.append(x[:, feat_init_idx].float().view(-1, 1))
            else:
                cols.append(
                    self.embeddings[cat_feat_counter](x[:, feat_init_idx].long())
                )
                cat_feat_counter += 1
        # concat
        post_embeddings = torch.cat(cols, dim=1)
        return post_embeddings

```

æ— è‡ªç›‘ç£å­¦ä¹ çš„TabNetçš„æ•´ä½“ç»“æ„åœ¨ TabNetNoEmbeddings ä¸­ï¼Œ  TabNetNoEmbeddings çš„ä»£ç å¦‚ä¸‹ã€‚
```python

class TabNetNoEmbeddings(torch.nn.Module):
    def __init__(self, input_dim, output_dim, n_d=8, n_a=8, n_steps=3, gamma=1.3, n_independent=2, n_shared=2,
                 epsilon=1e-15, virtual_batch_size=128, momentum=0.02, mask_type="sparsemax", ):
        """
        Defines main part of the TabNet network without the embedding layers.

        Parameters
        ----------
        input_dim : int
            Number of features
        output_dim : int or list of int for multi task classification
            Dimension of network output
            examples : one for regression, 2 for binary classification etc...
        n_d : int
            Dimension of the prediction  layer (usually between 4 and 64)
        n_a : int
            Dimension of the attention  layer (usually between 4 and 64)
        n_steps : int
            Number of successive steps in the network (usually between 3 and 10)
        gamma : float
            Float above 1, scaling factor for attention updates (usually between 1.0 to 2.0)
        n_independent : int
            Number of independent GLU layer in each GLU block (default 2)
        n_shared : int
            Number of independent GLU layer in each GLU block (default 2)
        epsilon : float
            Avoid log(0), this should be kept very low
        virtual_batch_size : int
            Batch size for Ghost Batch Normalization
        momentum : float
            Float value between 0 and 1 which will be used for momentum in all batch norm
        mask_type : str
            Either "sparsemax" or "entmax" : this is the masking function to use
        """
        super(TabNetNoEmbeddings, self).__init__()
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.is_multi_task = isinstance(output_dim, list)
        self.n_d = n_d
        self.n_a = n_a
        self.n_steps = n_steps
        self.gamma = gamma
        self.epsilon = epsilon
        self.n_independent = n_independent
        self.n_shared = n_shared
        self.virtual_batch_size = virtual_batch_size
        self.mask_type = mask_type
        self.initial_bn = BatchNorm1d(self.input_dim, momentum=0.01)

        self.encoder = TabNetEncoder(input_dim=input_dim, output_dim=output_dim, n_d=n_d, n_a=n_a, n_steps=n_steps,
                                     gamma=gamma, n_independent=n_independent, n_shared=n_shared, epsilon=epsilon,
                                     virtual_batch_size=virtual_batch_size, momentum=momentum, mask_type=mask_type, )

        if self.is_multi_task:
            self.multi_task_mappings = torch.nn.ModuleList()
            for task_dim in output_dim:
                task_mapping = Linear(n_d, task_dim, bias=False)
                initialize_non_glu(task_mapping, n_d, task_dim)
                self.multi_task_mappings.append(task_mapping)
        else:
            self.final_mapping = Linear(n_d, output_dim, bias=False)
            initialize_non_glu(self.final_mapping, n_d, output_dim)

    def forward(self, x):
        res = 0
        steps_output, M_loss = self.encoder(x)
        res = torch.sum(torch.stack(steps_output, dim=0), dim=0)

        if self.is_multi_task:
            # Result will be in list format
            out = []
            for task_mapping in self.multi_task_mappings:
                out.append(task_mapping(res))
        else:
            out = self.final_mapping(res)
        return out, M_loss

    def forward_masks(self, x):
        return self.encoder.forward_masks(x)


```
ç”±äºæ˜¯æ— ç›‘ç£å­¦ä¹ ï¼Œæ‰€ä»¥åªæœ‰ encoder éƒ¨åˆ†ï¼Œæ²¡æœ‰ decoder éƒ¨åˆ†ï¼Œæˆ‘ä»¬å…¶å®å¯ä»¥æŠŠ decoder éƒ¨åˆ†åŠ è¿›æ¥ï¼Œå½“ä½œåé¢åˆ†ç±»å±‚ã€‚ä½†æ˜¯ç”±äº TabNet ä¸å…³å¿ƒåˆ†ç±»ä¸å›å½’ï¼Œæ‰€ä»¥è¿™é‡Œå°±æ²¡æœ‰ decoder ã€‚

ä»è®ºæ–‡ä¸­å¯ä»¥çœ‹åˆ°ï¼Œåœ¨ encoder ä¸­ï¼Œé¦–å…ˆæˆ‘ä»¬çš„æ•°æ®ä¼šè¿›å…¥åˆ° BN å±‚ï¼Œåœ¨ä»£ç ä¸­ï¼ŒBNçš„å®ç°å¹¶ä¸æ˜¯ä½¿ç”¨çš„å¸¸ç”¨çš„BNï¼Œè€Œæ˜¯ä½¿ç”¨çš„ [GBNï¼ˆGhost Batch Normalizationï¼‰](https://7568.github.io/2021/12/02/2021-11-06-neural-network-architecture.html) ã€‚ç„¶åæ•°æ®ä¼šåˆ†ä¸¤å¤´åˆ†åˆ«è¿›å…¥åˆ° Feature transformer æ¨¡å—ä¸­å’Œ Mask æ¨¡å—ä¸­ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![tabnet-encoder-1]

Feature transformer çš„ä»£ç å¦‚ä¸‹ï¼š
```python
class FeatTransformer(torch.nn.Module):
    def __init__(
        self,
        input_dim,
        output_dim,
        shared_layers,
        n_glu_independent,
        virtual_batch_size=128,
        momentum=0.02,
    ):
        super(FeatTransformer, self).__init__()
        """
        Initialize a feature transformer.

        Parameters
        ----------
        input_dim : int
            Input size
        output_dim : int
            Output_size
        shared_layers : torch.nn.ModuleList
            The shared block that should be common to every step
        n_glu_independent : int
            Number of independent GLU layers
        virtual_batch_size : int
            Batch size for Ghost Batch Normalization within GLU block(s)
        momentum : float
            Float value between 0 and 1 which will be used for momentum in batch norm
        """

        params = {
            "n_glu": n_glu_independent,
            "virtual_batch_size": virtual_batch_size,
            "momentum": momentum,
        }

        if shared_layers is None:
            # no shared layers
            self.shared = torch.nn.Identity()
            is_first = True
        else:
            self.shared = GLU_Block(
                input_dim,
                output_dim,
                first=True,
                shared_layers=shared_layers,
                n_glu=len(shared_layers),
                virtual_batch_size=virtual_batch_size,
                momentum=momentum,
            )
            is_first = False

        if n_glu_independent == 0:
            # no independent layers
            self.specifics = torch.nn.Identity()
        else:
            spec_input_dim = input_dim if is_first else output_dim
            self.specifics = GLU_Block(
                spec_input_dim, output_dim, first=is_first, **params
            )

    def forward(self, x):
        x = self.shared(x)
        x = self.specifics(x)
        return x
```

Feature transformer ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤º

![tabnet-feature-transformer]

Feature transformer åˆ†æˆä¸¤ä¸ªéƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†ä¸º Shared across decision stepsï¼Œå°±æ˜¯ä»£ç ä¸­çš„self.sharedï¼Œå¦ä¸€éƒ¨åˆ†ä¸º Decision step dependentï¼Œå°±æ˜¯ä»£ç ä¸­çš„self.specificsï¼Œå®ƒä»¬é‡Œé¢éƒ½æ˜¯ç”±ä¸¤ä¸ª FC+BN+GLU ç»„æˆï¼Œåªæ˜¯è¿æ¥æ–¹å¼ä¸ä¸€æ ·ã€‚
åœ¨[dreamquark-ai çš„ä»£ç ä¸­](https://github.com/dreamquark-ai/tabnet) å°† FC+BN+GLU æ”¾åœ¨äº†ä¸€èµ·ï¼Œç»„æˆä¸€ä¸ª GLU_Layer ï¼ŒGLU_Layer ä»£ç å¦‚ä¸‹
```python
class GLU_Layer(torch.nn.Module):
    def __init__(
        self, input_dim, output_dim, fc=None, virtual_batch_size=128, momentum=0.02
    ):
        super(GLU_Layer, self).__init__()

        self.output_dim = output_dim
        if fc:
            self.fc = fc
        else:
            self.fc = Linear(input_dim, 2 * output_dim, bias=False)
        initialize_glu(self.fc, input_dim, 2 * output_dim)

        self.bn = GBN(
            2 * output_dim, virtual_batch_size=virtual_batch_size, momentum=momentum
        )

    def forward(self, x):
        x = self.fc(x)
        x = self.bn(x)
        out = torch.mul(x[:, : self.output_dim], torch.sigmoid(x[:, self.output_dim :]))
        return out

```

æˆ‘ä»¬çš„æ•°æ®ç»è¿‡äº† Feature transformer ä¹‹åï¼Œå¾—åˆ°çš„è¾“å‡ºä¸ºï¼š`[-0.5458,  0.1613,  0.0086, -1.0458,  0.6683, -0.5557, -0.3257,  0.1752, -0.5458, -0.3031,  0.7458, -0.1514, -0.1752, -0.3387,  0.1345, -0.1505]`ï¼Œæ­¤æ—¶æˆ‘ä»¬çš„è¾“å‡ºä¸º16ç»´ã€‚
ç„¶åæ•°æ®è¿›å…¥åˆ°splitï¼Œsplitå°†æ•°æ®ä»ç»´åº¦æ–¹å‘ä¸€åˆ†ä¸ºäºŒï¼Œä¸€éƒ¨åˆ†æ•°æ®ç»è¿‡RELUï¼Œè¿›å…¥åˆ°è¾“å‡ºç¯èŠ‚ï¼Œå¦ä¸€éƒ¨åˆ†è¿›å…¥åˆ° Attentive transformer ä¸­ã€‚

Attentive transformer ç»“æ„å›¾å¦‚ä¸‹æ‰€ç¤º

![tabnet-attentive-transformer]

æ•°æ®åœ¨ Attentive transformer ä¸­é¦–å…ˆæ˜¯ç»è¿‡ FC å’Œ GBNï¼Œç„¶åä¸ Prior scales ç›¸ä¹˜ï¼Œå¾—åˆ°ç»“æœä¹‹åï¼Œå†ç»è¿‡ Sparsemax å¾—åˆ°è¾“å‡ºã€‚å…¶ä¸­ Prior scales åˆå§‹å€¼ä¸ºå…¨ä¸º1çš„å‘é‡ï¼Œ
å½“æ•°æ®ç»è¿‡äº† encoder çš„ step 1 ä¹‹åï¼Œåœ¨ step 2 ä¸­ Prior scales å°±æ˜¯ Attentive transformer çš„è¾“å‡ºã€‚

Attentive transformer çš„ä»£ç å¦‚ä¸‹ï¼š
```python
class AttentiveTransformer(torch.nn.Module):
    def __init__(
        self,
        input_dim,
        output_dim,
        virtual_batch_size=128,
        momentum=0.02,
        mask_type="sparsemax",
    ):
        """
        Initialize an attention transformer.

        Parameters
        ----------
        input_dim : int
            Input size
        output_dim : int
            Output_size
        virtual_batch_size : int
            Batch size for Ghost Batch Normalization
        momentum : float
            Float value between 0 and 1 which will be used for momentum in batch norm
        mask_type : str
            Either "sparsemax" or "entmax" : this is the masking function to use
        """
        super(AttentiveTransformer, self).__init__()
        self.fc = Linear(input_dim, output_dim, bias=False)
        initialize_non_glu(self.fc, input_dim, output_dim)
        self.bn = GBN(
            output_dim, virtual_batch_size=virtual_batch_size, momentum=momentum
        )

        if mask_type == "sparsemax":
            # Sparsemax
            self.selector = sparsemax.Sparsemax(dim=-1)
        elif mask_type == "entmax":
            # Entmax
            self.selector = sparsemax.Entmax15(dim=-1)
        else:
            raise NotImplementedError(
                "Please choose either sparsemax" + "or entmax as masktype"
            )

    def forward(self, priors, processed_feat):
        x = self.fc(processed_feat)
        x = self.bn(x)
        x = torch.mul(x, priors)
        x = self.selector(x)
        return x

```
 
å½“æˆ‘ä»¬çš„æ•°æ®ç»è¿‡äº† Attentive transformer ä¹‹åï¼Œè¾“å‡ºçš„å°±æ˜¯ attention ï¼Œæ­¤æ—¶æˆ‘ä»¬å°†è¯¥ attention ä¸æœ€å¼€å§‹ç»è¿‡ BN ä¹‹åçš„ features ç›¸ä¹˜ï¼Œè¿™å°±æ˜¯ tabnet ç»“æ„å›¾ä¸­çš„ Mask æ“ä½œã€‚ç„¶åæˆ‘ä»¬å°† Mask ä¸­å¾—åˆ°çš„ç»“æœå½“ä½œè¾“å…¥ï¼Œæ”¾å…¥ Feature transformer ï¼Œç„¶åç»è¿‡ split å’Œ ReLU å¾—åˆ°è¾“å‡ºï¼ŒåŒæ—¶ split çš„ä¸€éƒ¨åˆ†ç»“æœ
å½“ä½œä¸‹ä¸€ä¸ª step çš„è¾“å…¥ã€‚è¯¥è¾“å‡ºè¿˜ç»è¿‡Aggæ“ä½œï¼Œä¸ä¹‹å‰çš„ Mask çš„ç»“æœè¿›è¡Œç›¸ä¹˜ï¼Œä½œä¸º Feature attribute çš„å…¶ä¸­ä¸€æ­¥ã€‚

[ğŸ’ INVASE ğŸ’](https://openreview.net/pdf?id=BJg_roAcK7) è®ºæ–‡ä¸­ç”¨å®éªŒè¯´æ˜äº†ä½¿ç”¨å¸¦é€‰æ‹©æ€§çš„featureæ¯”ä½¿ç”¨å…¨éƒ¨çš„featureæ•ˆæœè¦å¥½ã€‚

[ğŸ’ å¼ºåŒ–å­¦ä¹ RL ğŸ’](https://openreview.net/pdf?id=B1gJOoRcYQ)


