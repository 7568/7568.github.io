---
layout: blog
time-series-process: true
mathjax: true
background-image: https://7568.github.io/images/2021-11-26-tabnet/img.png
title:  TabNet: Attentive Interpretable Tabular Learning
category: time series 处理
tags:
- tabular data
- time series
---

[tabnet-architecture]:https://7568.github.io/images/2021-11-26-tabnet/tabnet-architecture.png

# 简介

TabNet 是2020年 Google Cloud AI 团队发表的一篇用来处理表格数据的深度神经网络模型，它可解释性强而且使用到了自监督技术，本文将
通过[💝 💝 💝 论文 💝 💝 💝](https://arxiv.org/pdf/1908.07442.pdf) 和[💝 💝 💝 代码 💝 💝 💝](https://github.com/dreamquark-ai/tabnet) 来对 TabNet 进行介绍。

# 论文介绍

TabNet 优点如下：
1. 方便使用，对原始数据不需要做任何其他的操作，就能直接使用，而且 TabNet 是端对端的，训练起来非常方便。
- TabNet 使用 attention 机制，使得模型的解释性强。
- TabNet 效果好，并且有两种不同的可解释性，一个是局部可解释性，一个是全局可解释性。
- 我们的非监督预训练模型对第一次见到的表格数据进行填词游戏有相当好的效果。

下图展示了 TabNet 的整体结构
![tabnet-architecture]

整体分为 encoder 和 decoder 两部分，在 encoder 中有两个特殊的结构，分别为 feature transformer，attentive transformer和 feature masking，其中 feature transformer 是
用来进行特征提取， attentive transformer 是用来进行特征选择，和提供对模型的可解释性，而 feature masking 是用来获取全局特征重要性的分布。
图中的（a）是encoder结构，（b）是 decoder 结构，（c）是 feature transformer，里面可以分成4层，其中2层为 Shared across decision steps，另外两层为 Decision step dependent，
（d）是 attentive transformer 结构，里面的 sparsemax 用来做归一化处理，并且结果中只包含突出的特征信息。



[强化学习](https://openreview.net/pdf?id=B1gJOoRcYQ)


