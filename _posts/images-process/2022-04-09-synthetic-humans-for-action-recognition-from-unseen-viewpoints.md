---
layout: blog
others: true
istop: true
title: "action recognition"
background-image: http://7568.github.io/images/2022-04-09-synthetic-humans-for-action-recognition-from-unseen-viewpoints.md/img.png
date:  2022-04-09
category: 视频动作识别
tags:
- video
- action recognition
- Synthetic data
---

[figure_1]:https://7568.github.io/images/2022-03-23-my-deep-compression-note/figure_1.png



[Synthetic Humans for Action Recognition from Unseen Viewpoints](https://arxiv.org/abs/1912.04070)
摘要：本文想通过利用合成的数据来提升视频人类动作的识别率。基于此想法，作者设计了一套合成数据的生成方法，生成了一个新的数据集，然后通过在该数据集上进行训练，再分别在NTU RGB+D 和 UESTC 数据集上做
微调，最后取得了目前动作识别最好准确率。NTU RGB+D 和 UESTC 数据集都是室内视频数据集，为了检验作者的方法，他们又在野外的视频数据集 Kinetics 上做了one-shot测试，即每一类只选择一个样本进行训练，然后取得了很好的效果。

Introduction：首先作者介绍通常大家都使用卷积神经网络CNN来对视频数据集UFC101进行动作识别训练和预测，但是作者提出卷积神经网络非常依赖于数据集的大小，通常需要很大的数据集才能有好的效果，然后鉴于此就有很多工作
提出使用合成数据来增加数据量，例如使用光流估计，分割，身体和手势估计。在本文中研究的是利用合成的数据来进行动作识别。

作者通过观察，发现对于现在流行的所有网络，对于同一个动作，如果训练和测试都使用同一个视角，能得到很好的结果，但是如果训练和测试使用不同的视角，这些网络的性能就会大幅度减少。例如作者使用一个3D的卷积网络来对 NTU RGB+D 数据集进行训练，
当训练和测试都是正面视角的时候，最终能得到80%多的准确率，但是如果我们的测试换成90度视角，这个时候准确率就只有40%了。这个结果激发了我们来从一个巧妙的视角研究视频动作识别。

在之前有一些对人体姿势预测进行了研究，并且取得了很好的成绩，通常他们的目的是动作捕获（MoCap），所以这些研究不适合于行为的预测，因为它们没有数据标记。

所以本文就提出了一个新的简单有效的方法来合成带有行为标签的数据。首先我们使用 HMMR 和 VIBE 等方法来动态的从单视角的 RGB 图像中得到 3D 的人，这些 3D 的人是由一串 SMPL 的人体姿势的参数组成。
然后我们通过 SMPL 合成不同视角的带标签的训练数据。最后我们使用一个 3D 网络来对我们的数据进行训练，得到了非常好的效果。我们的效果主要有两个方面，一是对于没见过的视角的行为识别，二是对于 one-shot 数据的训练识别。

----------------

Related Work： 人类行为识别是一个成熟的研究领域，在 Kong et al 的一篇对其研究的综述论文中有详细的介绍。本文中我们只聚焦于相关工作中的合成数据，交叉尺度动作识别，和简要的3D人类形态估计。

合成人类数据：在过去有很多研究都使用了合成数据来进行数据增强，但是他们都还没有将合成数据应用到人类行为识别上来，之前的一个重要的合成数据集 SURREAL ，
就是视频中人类 shape ， pose ， 和 motion 的数据集，而不是行为的识别。过去也有一些用姿势合成数据，和点轨迹合成数据来进行不同视角的行为识别，
但是利用合成的RGB图像来训练，来进行动作识别的研究还是一个比较新的领域，De Souza et al是最早的一批人来研究该领域。但是他们方法自动化程度不高。有一些地方
需要手动处理，而且他们的可扩展性不是很好。

之前有一篇论文（43）他们与我们的工作最相近，他们是利用合成的数据来学习人类姿势模型，然后通过该模型得到行为视频的特征，最后将该特征进行行为预测的分类。
我们与该论文的最大区别就是我们合成的数据是直接用来行为识别，也就是说我们生成的数据是带有行为标签的。

交叉视角的行为识别：NTU RGB+D 是第一个大规模多视角的行为识别数据集。从而使得我们可以开始在该领域使用深度神经网络。UESTC

----------------
SURREAL dataset：






 
[Learning from Synthetic Humans](https://arxiv.org/pdf/1701.01370.pdf) 对于图像分割，其中有一个任务是通过输入一张图像，能够分割出人的同时也要能分割出这个人在该图像中的景深信息。
对于这样一个任务，我们可用的数据集很少，于是本文就提出一个方法来人工合成一个数据集。这篇文章说我们使用 Blender 从 CMU MoCap 中获得 SMPL 人体参数信息，包括姿势和外形，然后通过改变人的衣服，环境，周围灯光，相机位置，最终合成大量的图像。

[Learning a Non-linear Knowledge Transfer Model for Cross-View Action Recognition](https://openaccess.thecvf.com/content_cvpr_2015/papers/Rahmani_Learning_a_Non-Linear_2015_CVPR_paper.pdf) 本文提出一种方法来将视频中不同角度运动转换到一个最常用的经典角度，
从而提升视频中动作识别的准确率。而且这个方法是一种无监督学习的方式。本文的出发点是希望这样做了之后，当我们在一个有限的数据集上训练一个网络，在测试的时候，如果我们碰到了一个动作，它的拍摄角度
是之前训练数据集里面没有的话，那么该网络就对这种视频的动作识别准确率很差，但是如果我们有个方法，能够使得所有的测试集在进入到网络之前都全部转换成我们最常见的经典角度，这个时候我们的网络
就可以很容易的识别该动作了。

(43)[Learning hu-man pose models from synthesized data for robust RGB-D action recognition]()