---
layout: blog
images-process: true
mathjax: true
title: "Shift-Net"
background-image: https://7568.github.io/images/2021-11-11-Shift-Net/img.png
date:  2021-11-11
category: 图像处理
tags:
- 神经网络
---
[Shift-Net-result]:https://7568.github.io/images/2021-11-11-Shift-Net/img.png
[shift-net-architecture]:https://7568.github.io/images/2021-11-11-Shift-Net/shift-net-architecture.png
[shift-operation]:https://7568.github.io/images/2021-11-11-Shift-Net/shift-operation.png

# 前言描述

最近看到个挺有意思的论文，是利用神经网络进行空白填充，由于我最近正好也在做图像去雨滴的研究，训练的模型整体上还看得过去，但是在雨滴部分总是模糊的，
所以我就想再弄个图像去模糊的网络加在后面，让模糊的地方变得清晰。本来是想用桑农老师的图像去模糊的研究成果的，之前听过一次他的报告，去模糊的效果很好，
不过现在看到了这篇论文，就先看看这个，也正好再研究一下GAN。

该论文的名字叫 Shift-Net: Image Inpainting via Deep Feature Rearrangement 可从[✨⭐✨这里✨⭐✨](https://openaccess.thecvf.com/content_ECCV_2018/papers/Zhaoyi_Yan_Shift-Net_Image_Inpainting_ECCV_2018_paper.pdf) 下载，
代码的地址在 [✨⭐✨这里✨⭐✨](https://github.com/Zhaoyi-Yan/Shift-Net_pytorch) ，模型的效果如下图所示，看上去还是很好的。

![Shift-Net-result]

其中 Navie Shift 是原始版本的效果，Flip Shift 是最新版本的效果，Flip Shift 不仅最终的效果好，而且速度也提升了很大，原理也更简单。

# 模型介绍

首先该模型解决的问题是给一张图像，然后遮住一部分，让模型来预测遮住的部分，学术上叫 image inpainting 。在图像处理上还有一个方向是 Style transfer，
改变图像的风格，在处理上与 image inpainting 有重合的地方，于是作者就将他们结合起来使用。

Shift-Net 也是 U-Net 结构的网络，不过他加了 shift connection 层。整体网络结构如下图：

![shift-net-architecture]

其中最特别的地方就是 shift connection ，其实本文使用的一个亮点还有一个，叫 guidance loss 。接下来我们将介绍文章中最主要的两个关键点 guidance loss 和 shift operation。

我们先定义输入为 $$I$$ , $$I_{gt}$$ 为 ground-truth image 。

## guidance loss

guidance loss 说是我们在计算我们的loss的时候，不是简单的用$$l_1$$或者$$l_2$$，而是参考之前[牛津大学的一篇论文](https://www.robots.ox.ac.uk/~vedaldi/assets/pubs/mahendran15understanding.pdf) 中，来针对神经网络的表示性设计损失。

设 $$\Omega$$ 为缺失的部分， $$\bar{\Omega}$$ 为已知部位，$$\Phi_l(I)$$ 表示第 l 层编码的特征，$$\Phi_{L-1}(I)$$ 表示第 l - 1 层的解码特征。
$$L^{gt}$$ 为最终的结果。我们期望 $$\Phi_l(I)$$ 和 $$\Phi_{L-1}(I)$$ 能传达 $$\Phi_l(I^{gt})$$ 中的所以信息。对于任何 $$y \in \Omega$$ 
我们都有 $$(\Phi_l(I))_y \approx 0$$ 。所以 $$(\Phi_{L-l}(I))_y$$ 就应该传达 $$(\Phi_l(I^{gt}))_y$$ 中的所以信息。
 
于是文章中就有了第一个 'guidance loss' ：

$$ \mathcal{L}_g = \displaystyle\sum_{y \in \Omega} \| ((\Phi_{L-l}(I))_y - (\Phi_l(I^{gt}))_y) \|_2^2$$

由于对于任意的已知区域的点，即当$$x \in \bar{\Omega}$$，有 $$(\Phi_{L-l}(I))_x \approx (\Phi_l(I^{gt}))_x$$，所以公式1中的$$y$$表示的是缺失部分的点，即$$y \in {\Omega}$$，
最终要使得 $$(\Phi_{L-l}(I))_y \approx (\Phi_l(I^{gt}))_y$$ ，通过拼接$$\Phi_l(I)$$和$$\Phi_{L-1}(I)$$就能够把$$(\Phi_l(I^{gt}))$$中的信息估计出来。

对于理想的结果$$H^{gt}$$为：

$$H^{gt} = \mathop{\arg\min}_H{\displaystyle\sum_{y \in \Omega} \| ((\Phi_{L-l}(I))_y - (\Phi_l(I^{gt}))_y) \|_2^2}$$

实际我们训练的的结果$$H^{de}$$为：

$$H^{de} = \mathop{\arg\min}_H{\displaystyle\sum_{y \in \Omega} \| ((\Phi_{L-l}(I))_y - (\Phi_l(I))_y) \|_2^2}$$

通过U型网络，通常可以使得$$H^{gt}$$和$$H^{de}$$很接近，但是往往$$H^{de}$$是模糊的。于是我们就使用到了本文的第二个关键点 shift operation

## shift operation

shift 的核心思想就是找图像中别的区域的点来填充未知区域的点。具体做法就是找相关性。从已知区域的特征中找于未知区域特征最近且相关性最大的来填充。过程示意图如下：

![shift-operation]

公式表示为如下：

$$x^{*}(y) = \mathop{\arg\max}_{x \in \bar{\Omega}} \frac{\langle (\Phi_{L-l}(I))_y , (\Phi_l(I))_x \rangle}{\| (\Phi_{L-l}(I))_y \|_2 \| (\Phi_l(I))_x \|_2}$$

得到 $$x^{*}(y)$$ 的值之后，然后 $$x^{*}(y) - y$$ 得到$$u_y$$，再将$$u_y$$拼装到$$(\Phi_{l}(I))_y$$中。

该模型也用到了GAN，但是作者在论文中没有做过多的介绍。

整个 Shift-Net 网络模型就介绍完毕了，接下来介绍代码部分。

# 代码



