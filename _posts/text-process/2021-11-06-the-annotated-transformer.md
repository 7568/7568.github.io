---
layout: blog
text-process: true
background-image: http://7568.github.io/images/2021-11-06-the-annotated-transformer/img.png
category: 文本处理
title: 机器翻译 - The Annotated Transformer
tags:
- transformer
- self-attention
- 文本处理
---

<iframe   src="https://7568.github.io/htmls/2021-11-06-the-annotated-transformer.html" id="external-frame" style="width:100%;" onload="setIframeHeight(this)" >
The Transformer from “Attention is All You Need” has been on a lot of people’s minds over the last year. Besides producing major improvements in translation quality, it provides a new architecture for many other NLP tasks. The paper itself is very clearly written, but the conventional wisdom has been that it is quite difficult to implement correctly.
</iframe>