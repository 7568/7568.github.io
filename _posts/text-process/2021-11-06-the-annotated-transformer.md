---
layout: blog
text-process: true
background-image: http://7568.github.io/images/2021-11-03_2.png
category: 文本处理
title: 机器翻译 - Seq2Seq with Attention
tags:
- Seq2Seq
- Attention
- 文本处理
- 2021-11-04-pynb_test.md
---

<iframe   src="https://7568.github.io/htmls/2021-11-06-the-annotated-transformer.html" id="external-frame" style="width:100%;" onload="setIframeHeight(this)" >
The Transformer from “Attention is All You Need” has been on a lot of people’s minds over the last year. Besides producing major improvements in translation quality, it provides a new architecture for many other NLP tasks. The paper itself is very clearly written, but the conventional wisdom has been that it is quite difficult to implement correctly.
</iframe>