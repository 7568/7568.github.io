---
layout: blog
text-process: true
background-image: http://7568.github.io/images/2021-11-15-cnn-seq2seqModel/img.png
category: æ–‡æœ¬å¤„ç†
title: æœºå™¨ç¿»è¯‘ - Seq2Seq with Attention
mathjax: true
tags:
- Seq2Seq
- Attention
- æ–‡æœ¬å¤„ç†
---

[convseq2seq0]:http://7568.github.io/images/2021-11-15-cnn-seq2seqModel/convseq2seq0.png
[convseq2seq1]:http://7568.github.io/images/2021-11-15-cnn-seq2seqModel/convseq2seq1.png

# ç®€ä»‹

åœ¨[ğŸ’ ä¸Šä¸€ç¯‡blog ğŸ’ ](https://7568.github.io/2021/11/03/rnn-seq2seqModel.html) ä¸­æˆ‘ä»¬è®²è¿°äº†ä½¿ç”¨rnnæ¥è¿›è¡Œè‡ªç„¶è¯­è¨€çš„ç¿»è¯‘å·¥ä½œï¼Œé™äºç¯‡å¹…çš„åŸå› ï¼Œæˆ‘ä»¬å°†ä¼šåœ¨æœ¬blogæ¥è®²è¿°ä½¿ç”¨ cnn è¿›è¡Œè‡ªç„¶è¯­è¨€çš„ç¿»è¯‘å·¥ä½œã€‚æˆ‘ä»¬å°†ä¼šåœ¨[ğŸ’ ä¸‹ä¸€ç¯‡ ğŸ’ ]() è¿›è¡Œ Transformer çš„è®²è§£ã€‚

æœ¬æ–‡æˆ‘ä»¬å°†ä¼šåœ¨æœ¬blogä¸­å®ç° [Convolutional Sequence to Sequence Learning ]() è®ºæ–‡ä¸­çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•ä¸æˆ‘ä»¬çš„ä¹‹å‰çš„æ–¹æ³•å®Œå…¨ä¸ä¸€æ ·ï¼Œåœ¨ä¹‹å‰çš„æ–¹æ³•ä¸­æˆ‘ä»¬
ä½¿ç”¨çš„éƒ½æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ä¸­å¸¸ç”¨çš„å¾ªç¯ç¥ç»ç½‘ç»œrnnï¼Œè€Œæœ¬æ–‡ä½¿ç”¨çš„æ˜¯é€šå¸¸ä½¿ç”¨åœ¨å›¾åƒå¤„ç†ä¸­ä»»åŠ¡ä¸­çš„å·ç§¯ç¥ç»ç½‘ç»œcnnã€‚ä¸è¿‡ä¸é€šå¸¸åœ¨å›¾åƒä¸­ä½¿ç”¨çš„cnnä¸åŒçš„æ˜¯ï¼Œåœ¨å›¾åƒä¸­cnnçš„å·ç§¯æ ¸é€šå¸¸
æ˜¯å¸¦æœ‰å®½åº¦å’Œé«˜åº¦çš„ï¼Œä½†æ˜¯åœ¨æ–‡æœ¬å¤„ç†ä»»åŠ¡ä¸­çš„cnnå·ç§¯æ ¸åªæœ‰é•¿åº¦ï¼Œæ²¡æœ‰é«˜åº¦ã€‚åœ¨[ğŸ’ æ­¤å¤„ ğŸ’ ](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb) æœ‰å…³äºcnnçš„ä»‹ç»ã€‚

# å‡†å¤‡æ•°æ®

é¦–å…ˆæˆ‘ä»¬è¿˜æ˜¯å‡†å¤‡æ•°æ®ï¼Œè¯¥éƒ¨åˆ†ä¸[ ğŸ’ ä¹‹å‰ ğŸ’ ](https://7568.github.io/2021/11/03/rnn-seq2seqModel.html) çš„å†…å®¹ä¸€è‡´ï¼Œå°±ä¸åšè¿‡å¤šè®²è§£ã€‚

# æ¨¡å‹ä»‹ç»

ä½¿ç”¨cnnè¿›è¡Œæ–‡æœ¬ç¿»è¯‘å·¥ä½œï¼Œæˆ‘ä»¬çš„æ¨¡å‹è¿˜æ˜¯åˆ†æˆ encoder å’Œ decoder ä¸¤éƒ¨åˆ†ï¼Œç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

![convseq2seq0]

## encoder

æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹ encoder çš„ç»“æ„

![convseq2seq1]

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°åœ¨ encoder ä¸­æœ‰ä¸€ä¸ªå¾ˆå¤§çš„ç‰¹ç‚¹å°±æ˜¯ä½ç½®çš„æ“ä½œï¼Œä¹‹å‰æˆ‘ä»¬çš„rnnä¸­éƒ½æ²¡æœ‰ä½ç½®ç¼–ç ï¼Œæ˜¯å› ä¸ºrnnå¤©ç„¶å°±æœ‰å…ˆåé¡ºåºï¼Œè€Œcnnæ²¡æœ‰ï¼Œ
è€Œæˆ‘ä»¬è‡ªç„¶è¯­è¨€æ˜¯æœ‰é¡ºåºçš„ï¼Œç›¸åŒçš„å•è¯å¯èƒ½ä¼šå› ä¸ºé¡ºåºçš„ä¸ä¸€æ ·ï¼Œç»„æˆçš„å¥å­çš„æ„æ€å¯èƒ½ä¼šå®Œå…¨ä¸ä¸€æ ·ã€‚æ‰€ä»¥åœ¨cnnä¸­éœ€è¦å¯¹è¾“å…¥è¿›è¡Œä½ç½®ç¼–ç ã€‚

åœ¨ encoder ä¸­æˆ‘ä»¬çš„è¾“å…¥åˆ†ä¸º6ä¸ªéƒ¨åˆ†:
1. å°†è¾“å…¥è¿›è¡ŒtokenåŒ–ï¼Œå°±æ˜¯å°†å­—ç¬¦è½¬æ¢æˆæ•°å­—ã€‚å†æ‹¼æ¥ä¸Šä½ç½®ç¼–ç 
- å°†ä½ç½®ç¼–ç ä¸tokenè¿›è¡Œé€ç‚¹ç›¸åŠ ï¼Œå¾—åˆ°å¸¦ä½ç½®å±æ€§çš„token
- å°†ä¸Šä¸€æ­¥çš„ç»“æœè¿›è¡Œå…¨è¿æ¥æ“ä½œ
- å°†ä¸Šä¸€æ­¥çš„ç»“æœè¿›è¡Œå·ç§¯æ“ä½œï¼Œå¾—åˆ°ç¬¬ä¸€ä¸ªç»“æœï¼Œä¸ºå·ç§¯å±‚çš„è¾“å‡º "conved output"
- å°†ä¸Šä¸€æ­¥çš„ç»“æœä¸ç¬¬äºŒæ­¥çš„ç»“æœè¿›è¡Œé€ç‚¹ç›¸åŠ ï¼Œå¾—åˆ°ç¬¬äºŒä¸ªç»“æœï¼Œç§°ä¸º "combined output"

åœ¨ rnn ä¸­æˆ‘ä»¬çš„ encoder åªä¼šæœ‰ä¸€ä¸ªç»“æœä¼ åˆ° decoder ä¸­ï¼Œè€Œåœ¨ cnn ä¸­æˆ‘ä»¬æœ‰ä¸¤ä¸ªç»“æœï¼Œåˆ†åˆ«æ˜¯"conved output"å’Œ"combined output"ï¼Œéƒ½ä¼šä½œä¸ºå‚æ•°ä¼ åˆ° decoder ä¸­å»ã€‚

åœ¨ä¸Šé¢æˆ‘ä»¬æè¿°çš„æ˜¯åªæœ‰ä¸€å±‚ cnn çš„ç½‘ç»œï¼Œå¦‚æœæƒ³æœ‰å¤šå±‚ï¼Œå…¶ä¸­ä¸€ä¸ªç®€å•çš„æ–¹æ³•æ˜¯ç›´æ¥åœ¨ç¬¬4æ­¥åŠ ä¸Šå¤šå±‚ç½‘ç»œï¼Œæœ¬æ–‡å°†ä»‹ç»ä¸€ä¸ªå¸¦æ®‹å·®å—çš„ cnn ç½‘ç»œæ¨¡å‹ï¼Œç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![convseq2seq1]

åœ¨ä¸Šå›¾ä¸­ç»¿è‰²çš„æ–¹å—è¡¨ç¤ºgated linear units (GLU)æ“ä½œï¼Œè¯¥æ“ä½œä¹Ÿæ˜¯è·Ÿ GRU å’Œ LSTM ä¸€æ ·ï¼Œå¸¦æœ‰é—¨æ§å•å…ƒï¼Œæ˜¯ä¸€ç§å¸¦é—¨æ§çš„æ¿€æ´»å‡½æ•°ã€‚

# ä»£ç ä¸‹è½½

ä»[bentrevett / pytorch-seq2seq](https://github.com/bentrevett/pytorch-seq2seq) ä¸­æå–å‡ºçš„ä»£ç å¦‚ä¸‹ï¼š

ğŸ‘‰ï¸ ğŸ‘‰ï¸ ğŸ‘‰ï¸ ç‚¹å‡»[ ğŸ’ ğŸ’ ğŸ’ å¯ä»¥ç›´æ¥ä¸‹è½½ä½¿ç”¨ LSTM ç»“æ„çš„ seq2seq æ¨¡å‹çš„ä»£ç ](https://7568.github.io/codes/text-process/2021-11-03-seq2seqModel-lstm.py)ã€‚å°†ä»£ç ä¸­ `is_train = False` æ”¹æˆ `is_train = True` å°±å¯ä»¥è®­ç»ƒäº†ï¼Œæµ‹è¯•çš„æ—¶å€™å†æ”¹å›æ¥å³å¯ã€‚



æ›´å¤šå‚è€ƒèµ„æ–™æ¥è‡ªäº
- [Towards Data Science - Attention â€” Seq2Seq Models](https://towardsdatascience.com/day-1-2-attention-seq2seq-models-65df3f49e263)
- [Sequence to Sequence Learning with Neural Networks](https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb)
-[Jay Alammar Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)



